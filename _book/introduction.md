# Introduction {#intro}

## Outline

The book will be divided into 3 main parts. This book will make the rather arbitrary distinction between *machine learning methods* and *deep learning methods* by saying that deep learning is any kind of multi-layer neural network (LSTM, bi-LSTM, CNN), while machine learning in anything else (Bayes, SVM, random forest). This partition was done as the different methods uses different packages and modeling infrastructure and from a pragmatic point of view it was deemed reasonable to split it up this way. Some of the topics will overlap between the second and third as the are different approaches to the tasks.

- **Natural language features**, walk-though of the ways and  struggles from going from strings to numbers. Will go though many different preprocessing steps will be be using later in the book while commenting on the pros and cons.

- **Machine learning methods**, we will investigate the power of some of the simple and more light-weight models in our arsenal.

- **Deep learning methods**, given more time and resources we see what we can achieve once we turn to neural networks. 

## What you wont see in this book

TODO (expand section)

- Speech processing
- Machine Translation
- Text to Speech
- Image Understanding
- Text generation (maybe)

## Code

All the code used in this book will be found in the [github repository](https://github.com/EmilHvitfeldt/tidy-nlp-in-R-book).  

The end of this book contains a software bibliography with descriptions of the software and packages being used. Each chapter/section will start by loading the packages used within. For further explanation please refer to the back.

## Related literature

- [Text Mining with R](https://www.tidytextmining.com/) Brilliant book by Julia Silge and David Robinson concerning text mining using the tidy framework. Accompanied with the [tidytext](https://CRAN.R-project.org/package=tidytext) package.

## Acknowledgements
